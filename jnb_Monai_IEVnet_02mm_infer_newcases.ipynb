{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This notebook assumes the following package versions:\n",
    "\n",
    "MONAI version: 0.3.0rc4\n",
    "Python version: 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21)  [GCC 7.3.0]\n",
    "OS version: Linux (4.15.0-144-generic)\n",
    "Numpy version: 1.19.1\n",
    "Pytorch version: 1.7.0a0+8deb4fe\n",
    "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
    "\n",
    "Optional dependencies:\n",
    "Pytorch Ignite version: 0.4.2\n",
    "Nibabel version: 3.1.1\n",
    "scikit-image version: 0.15.0\n",
    "Pillow version: 7.2.0\n",
    "Tensorboard version: 1.15.0+nv\n",
    "gdown version: 3.12.2\n",
    "TorchVision version: 0.8.0a0\n",
    "ITK version: 5.1.1\n",
    "tqdm version: 4.50.0\n",
    "\n",
    "For details about installing the optional dependencies, please visit:\n",
    "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
    "\n",
    "Later MONAI/PyTorch versions are likely to have slight changes in syntax.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.data import ITKReader\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    CenterSpatialCrop,\n",
    "    LoadNifti,\n",
    "    LoadImage,\n",
    "    AddChannel,\n",
    "    AsChannelFirst,\n",
    "    AsChannelLast,\n",
    "    SpatialPad,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEVnetInferer():\n",
    "    '''\n",
    "        instantiate ievnet=IEVnetInferer()\n",
    "        call ievnet.predict(filenames_in, filenames_out) for prediction of a list of volumes\n",
    "        assumes input and writes output volumes of dimensions [200,150,100] at 0.2mm resolution\n",
    "    '''\n",
    "    def __init__(self, device='cpu'):\n",
    "        # using MONAI Unet implementation for cuda optimizations\n",
    "        # parametrize UNet like VNet (see: https://arxiv.org/abs/1606.04797): \n",
    "        #   - 4x downsampling\n",
    "        #   - 16/32/64/128/256 filter channels, \n",
    "        #   - down/up-convolutions with stride 2 instead of max-pooling/up-pooling\n",
    "        #   - number of residual units in each layer: 2 \n",
    "        #   - Dice loss\n",
    "        if device=='cuda':\n",
    "            if not torch.cuda.is_available():\n",
    "                print('Cuda not available, falling back to CPU inference.')\n",
    "                device='cpu'\n",
    "        \n",
    "        print('Loading IEVNet model...')\n",
    "        self.model = monai.networks.nets.UNet(\n",
    "                        dimensions=3,\n",
    "                        in_channels=1,\n",
    "                        out_channels=1,\n",
    "                        channels=(16, 32, 64, 128, 256),\n",
    "                        strides=(2, 2, 2, 2),\n",
    "                        dropout=0.5,\n",
    "                        num_res_units=2).to(device)\n",
    "        self.model.load_state_dict(torch.load('best_metric_model.pth'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.transforms = Compose([LoadNifti(image_only=True),\n",
    "                                   AddChannel(),\n",
    "                                   SpatialPad(spatial_size=[208, 160, 112]),\n",
    "                                   ScaleIntensity(),\n",
    "                                   AddChannel(),\n",
    "                                   ToTensor(),])\n",
    "        \n",
    "        # post-processing: center-cropping back to 200,150,100 voxels\n",
    "        self.cropper = CenterSpatialCrop([200, 150, 100])\n",
    "        \n",
    "        print('Done loading model - IEVNet ready.')\n",
    "    \n",
    "    def predict(self, filenames_in, filenames_out):\n",
    "        # create dataset and loader on the fly\n",
    "        dataset = monai.data.ArrayDataset(filenames_in, img_transform=self.transforms)\n",
    "        saver = monai.data.NiftiSaver(resample=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # run seg inference (only one file in dataset)\n",
    "            for idx, img in enumerate(dataset): \n",
    "                print('Infering volume %d of %d (%s)'%(idx+1, len(filenames_in), filenames_in[idx]))\n",
    "                # predict\n",
    "                pred_raw = self.model(img)\n",
    "                print('Inference done.')\n",
    "                # apply sigmoid\n",
    "                sigmoid = torch.nn.Sigmoid()\n",
    "                pred_sigmoid = sigmoid(pred_raw)\n",
    "                # post-processing of results\n",
    "                pred = self.cropper(torch.squeeze(pred_sigmoid,0))\n",
    "                # export\n",
    "                # get original ITK image header info\n",
    "                print('Saving.')\n",
    "                reader = monai.data.ITKReader()\n",
    "                img = reader.read(filenames_in[idx])\n",
    "                img_arr, img_hdr = reader.get_data(img)\n",
    "                meta_data = img_hdr\n",
    "                meta_data['filename_or_obj'] = filenames_out[idx]\n",
    "                #saver.save(pred,meta_data)\n",
    "                monai.data.write_nifti(pred.squeeze().cpu().numpy(), filenames_out[idx], affine=meta_data['affine'], resample=False)\n",
    "                print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample inference on two example volumes\n",
    "ievnet = IEVnetInferer()\n",
    "filenames_in  = ['./sample_data/vol_ie_L.nii.gz', \n",
    "                 './sample_data/vol_ie_R.nii.gz']\n",
    "filenames_out = ['./sample_data/seg_ie_L.nii.gz', \n",
    "                 './sample_data/seg_ie_R.nii.gz']\n",
    "ievnet.predict(filenames_in, filenames_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
