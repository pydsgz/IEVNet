{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This notebook assumes the following package versions:\n",
    "\n",
    "MONAI version: 0.2.0+166.g12b3fbf\n",
    "Python version: 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21)  [GCC 7.3.0]\n",
    "Numpy version: 1.19.5\n",
    "Pytorch version: 1.7.1\n",
    "\n",
    "Optional dependencies:\n",
    "Pytorch Ignite version: 0.3.0\n",
    "Nibabel version: 3.1.1\n",
    "scikit-image version: 0.15.0\n",
    "Pillow version: 7.2.0\n",
    "Tensorboard version: 1.15.0+nv\n",
    "gdown version: 3.12.2\n",
    "TorchVision version: 0.8.0a0\n",
    "ITK version: 5.1.1\n",
    "\n",
    "Later MONAI/PyTorch versions are likely to have slight changes in syntax.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import monai\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import create_test_image_3d, list_data_collate, ITKReader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    AsChannelFirstd,\n",
    "    AsChannelLastd,\n",
    "    AddChanneld,\n",
    "    RandAdjustContrastd,\n",
    "    Compose,\n",
    "    DivisiblePadd,\n",
    "    LoadNiftid,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotated,\n",
    "    RandZoomd,\n",
    "    RandFlipd,\n",
    "    RandShiftIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    RandAffined,\n",
    "    Rand3DElasticd,\n",
    "    RandGaussianNoised,\n",
    "    ScaleIntensityd,\n",
    "    SpatialPadd,\n",
    "    ToTensord,\n",
    "    DataStats,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "import itk\n",
    "\n",
    "monai.config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEVnetInferer():\n",
    "    '''\n",
    "        instantiate ievnet=IEVnetInferer()\n",
    "        call ievnet.predict(filenames_in, filenames_out) for prediction of a list of volumes\n",
    "        assumes input and writes output volumes of dimensions [200,150,100] at 0.2mm resolution\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        print('Loading IEVNet model...')\n",
    "        # using MONAI Unet implementation for cuda optimizations\n",
    "        # parametrize UNet like VNet (see: https://arxiv.org/abs/1606.04797): \n",
    "        #   - 4x downsampling\n",
    "        #   - 16/32/64/128/256 filter channels, \n",
    "        #   - down/up-convolutions with stride 2 instead of max-pooling/up-pooling\n",
    "        #   - number of residual units in each layer: 2 \n",
    "        #   - Dice loss\n",
    "        self.model = monai.networks.nets.UNet(\n",
    "                        dimensions=3,\n",
    "                        in_channels=1,\n",
    "                        out_channels=1,\n",
    "                        channels=(16, 32, 64, 128, 256),\n",
    "                        strides=(2, 2, 2, 2),\n",
    "                        dropout=0.5,\n",
    "                        num_res_units=2).to(device)\n",
    "        self.model.load_state_dict(torch.load('best_metric_model.pth'))\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.transforms = Compose([LoadNifti(),\n",
    "                                   AddChannel(),\n",
    "                                   SpatialPad(spatial_size=[208, 160, 112]),\n",
    "                                   ScaleIntensity(),\n",
    "                                   ToTensor(),])\n",
    "        \n",
    "        # post-processing: center-cropping back to 200,150,100 voxels\n",
    "        self.cropper = monai.transforms.CenterSpatialCrop([200, 150, 100])\n",
    "        \n",
    "        print('Done loading model - IEVNet ready.')\n",
    "    \n",
    "    def predict(self, filenames_in, filenames_out):\n",
    "        # create dataset and loader on the fly\n",
    "        dataset = monai.data.ArrayDataset(data=filenames_in, transform=self.transforms)\n",
    "        loader = DataLoader(dataset, batch_size=1, collate_fn=list_data_collate)\n",
    "        saver = monai.data.NiftiSaver(resample=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # run seg inference (only one file in dataset)\n",
    "            for idx, img in enumerate(dataset): \n",
    "                # predict\n",
    "                pred_raw = self.model(img)\n",
    "                # apply sigmoid\n",
    "                pred_sigmoid = torch.nn.Sigmoid(pred_raw)\n",
    "                # post-processing of results\n",
    "                pred = self.cropper(pred_sigmoid)\n",
    "                # export\n",
    "                # get original ITK image header info\n",
    "                reader = monai.data.ITKReader()\n",
    "                img = reader.read(ff_img)\n",
    "                img_arr, img_hdr = reader.get_data(img)\n",
    "                meta_data = img_hdr\n",
    "                meta_data['filename_or_obj'] = filenames_out[idx]\n",
    "                saver.save(np_sigmoid(pred),meta_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample inference on two example volumes\n",
    "ievnet = IEVnetInferer()\n",
    "filenames_in  = ['/path/to/my/testfile/vol_01.nii.gz', \n",
    "                 '/path/to/my/testfile/vol_02.nii.gz']\n",
    "filenames_out = ['/path/to/my/testfile/pred_01.nii.gz', \n",
    "                 '/path/to/my/testfile/pred_02.nii.gz']\n",
    "ievnet.predict(filenames_in, filenames_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
