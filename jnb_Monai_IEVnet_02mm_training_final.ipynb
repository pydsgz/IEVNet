{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "This notebook was executed with the following package versions:\n",
    "\n",
    "MONAI version: 0.2.0+166.g12b3fbf\n",
    "Python version: 3.6.10 |Anaconda, Inc.| (default, May  8 2020, 02:54:21)  [GCC 7.3.0]\n",
    "Numpy version: 1.19.5\n",
    "Pytorch version: 1.7.1\n",
    "\n",
    "Optional dependencies:\n",
    "Pytorch Ignite version: 0.3.0\n",
    "Nibabel version: 3.1.1\n",
    "scikit-image version: 0.15.0\n",
    "Pillow version: 7.2.0\n",
    "Tensorboard version: 1.15.0+nv\n",
    "gdown version: 3.12.2\n",
    "TorchVision version: 0.8.0a0\n",
    "ITK version: 5.1.1\n",
    "\n",
    "Later MONAI/PyTorch versions are likely to have slight changes in syntax.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "import monai\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import create_test_image_3d, list_data_collate, ITKReader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.inferers import SimpleInferer\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    AsChannelFirstd,\n",
    "    AsChannelLastd,\n",
    "    AddChanneld,\n",
    "    RandAdjustContrastd,\n",
    "    Compose,\n",
    "    DivisiblePadd,\n",
    "    LoadNiftid,\n",
    "    LoadImaged,\n",
    "    RandCropByPosNegLabeld,\n",
    "    RandRotated,\n",
    "    RandZoomd,\n",
    "    RandFlipd,\n",
    "    RandShiftIntensityd,\n",
    "    RandScaleIntensityd,\n",
    "    RandAffined,\n",
    "    Rand3DElasticd,\n",
    "    RandGaussianNoised,\n",
    "    ScaleIntensityd,\n",
    "    SpatialPadd,\n",
    "    ToTensord,\n",
    "    DataStats,\n",
    ")\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "import itk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect files for train/valid/test sets into lists\n",
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# load dataset\n",
    "dpath = '/data/IEVnet/train'\n",
    "data = []\n",
    "\n",
    "# create a list of volume/segmentation pairs in training data\n",
    "img_path_pattern = os.path.join(dpath, \"subject_*\")\n",
    "for subject_base in sorted(glob(img_path_pattern)):\n",
    "    imgL = os.path.join(subject_base, \"vol_L_02mm.nii.gz\")\n",
    "    imgR = os.path.join(subject_base, \"vol_R_02mm.nii.gz\")\n",
    "    segL = os.path.join(subject_base, \"seg_L_02mm.nii.gz\")\n",
    "    segR = os.path.join(subject_base, \"seg_R_02mm.nii.gz\")\n",
    "    data += [{\"img\": imgL, \"seg\": segL},\n",
    "             {\"img\": imgR, \"seg\": segR}]\n",
    "\n",
    "# create another dataset for the test data:\n",
    "test_subject_ids = sorted(['D2_01', 'D2_02', 'D2_03', 'D2_04', 'D2_05', \n",
    "                           'D2_06', 'D2_07', 'D2_08', 'D2_09', 'D2_10', \n",
    "                           'D3_01', 'D3_02', 'D3_03', 'D3_04', 'D3_05', \n",
    "                           'D3_06', 'D3_07', 'D3_08', 'D3_09', 'D3_10', \n",
    "                           'D4_01', 'D4_02', 'D4_03', 'D4_04', 'D4_05', \n",
    "                           'D4_06', 'D4_07', 'D4_08', 'D4_09', 'D4_10', \n",
    "                           'D5_01', 'D5_02', 'D5_03', 'D5_04', 'D5_05', \n",
    "                           'D5_06', 'D5_07', 'D5_08', 'D5_09', 'D5_10'])\n",
    "\n",
    "pn_test = '/data/IEVnet/test'\n",
    "data_test = []\n",
    "for idx, sid in enumerate(test_subject_ids):\n",
    "    for side in ['L','R']:\n",
    "        # volume\n",
    "        ff_img = os.path.join(pn_test, sid, 'vol_%s_02mm.nii.gz'%side)\n",
    "        # manual groundtruth segmentation (used for computation of test metrics, Dice etc.)\n",
    "        ff_seg = os.path.join(pn_test, sid, 'seg_%s_02mm.nii.gz'%side)\n",
    "        if os.path.exists(ff_img):\n",
    "            data_test.append({\"img\": ff_img, \n",
    "                              \"seg\": ff_seg})\n",
    "print('Number of vols in test-set: %d. Expected: 80 (40 subjects, L/R IEs).'%(len(data_test)))\n",
    "\n",
    "val_fraction = 0.1\n",
    "idx_val_split = int(len(data)*(1-val_fraction))\n",
    "print('Number of subjects in train set: %d'%(len(data[:idx_val_split])))\n",
    "print('Number of subjects in valid set: %d'%(len(data[idx_val_split:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training data into train/val\n",
    "data_train = data[:idx_val_split]\n",
    "data_val = data[idx_val_split:]\n",
    "\n",
    "# determine max rot/trans limits in augmentation\n",
    "vol_size = np.array([200, 150, 100])\n",
    "rot_max = 20*np.pi/180.0\n",
    "trans_max = tuple((vol_size*0.15).astype(int))\n",
    "\n",
    "# define transforms for image and segmentation during training (augmentation)\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "        SpatialPadd(keys=[\"img\", \"seg\"],spatial_size=[208, 160, 112]),\n",
    "        ScaleIntensityd(keys=\"img\"),\n",
    "        RandAdjustContrastd(keys=\"img\", prob=0.9, gamma=(0.3, 1.5)),\n",
    "        RandGaussianNoised(keys=\"img\", prob=0.5),\n",
    "        RandFlipd(keys=[\"img\",\"seg\"],prob=0.5, spatial_axis=[0]),\n",
    "        ToTensord(keys=[\"img\", \"seg\"]),\n",
    "        Rand3DElasticd(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "            prob=0.75,\n",
    "            sigma_range=(5, 8),\n",
    "            magnitude_range=(5, 100),\n",
    "            translate_range=trans_max,\n",
    "            rotate_range=(rot_max,rot_max,rot_max),\n",
    "            scale_range=(0.15, 0.15, 0.15),\n",
    "            padding_mode=\"border\",\n",
    "        ),        \n",
    "    ]\n",
    ")\n",
    "\n",
    "# define transforms for image and segmentation during validation/testing\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"img\", \"seg\"]),\n",
    "        AddChanneld(keys=[\"img\", \"seg\"]),\n",
    "        SpatialPadd(keys=[\"img\", \"seg\"],spatial_size=[208, 160, 112]),\n",
    "        ScaleIntensityd(keys=\"img\"),\n",
    "        ToTensord(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check a few example augmentations/transforms with a temporary DataLoader\n",
    "for i in range(10):\n",
    "    check_ds = monai.data.Dataset(data=data_train, transform=train_transforms)\n",
    "    check_loader = DataLoader(check_ds, batch_size=1)\n",
    "    check_data = monai.utils.first(check_loader)\n",
    "    image, label = (check_data[\"img\"][0][0], check_data[\"seg\"][0][0])\n",
    "    print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "    # plot the slice [:, :, slice_idx]\n",
    "    slice_idxs = (np.array([208, 160, 112])/2).astype(int)\n",
    "    plt.figure(\"check\", (12, 6))\n",
    "    # plot along 1st axis\n",
    "    slice_idx = slice_idxs[0]\n",
    "    plt.subplot(3, 2, 1)\n",
    "    plt.title(\"img\")\n",
    "    plt.imshow(np.squeeze(image[slice_idx, :, :]), cmap=\"gray\", vmin=0.0, vmax=1.0)\n",
    "    plt.subplot(3, 2, 2)\n",
    "    plt.title(\"seg\")\n",
    "    plt.imshow(np.squeeze(label[slice_idx, :, :]))\n",
    "    # plot along 2nd axis\n",
    "    slice_idx = slice_idxs[1]\n",
    "    plt.subplot(3, 2, 3)\n",
    "    plt.title(\"img\")\n",
    "    plt.imshow(np.squeeze(image[:, slice_idx, :]), cmap=\"gray\", vmin=0.0, vmax=1.0)\n",
    "    plt.subplot(3, 2, 4)\n",
    "    plt.title(\"seg\")\n",
    "    plt.imshow(np.squeeze(label[:, slice_idx, :]))\n",
    "    # plot along 3rd axis\n",
    "    slice_idx = slice_idxs[1]\n",
    "    plt.subplot(3, 2, 5)\n",
    "    plt.title(\"img\")\n",
    "    plt.imshow(np.squeeze(image[:, :, slice_idx]), cmap=\"gray\", vmin=0.0, vmax=1.0)\n",
    "    plt.subplot(3, 2, 6)\n",
    "    plt.title(\"seg\")\n",
    "    plt.imshow(np.squeeze(label[:, :, slice_idx]))\n",
    "    # show\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define dataset, data loader\n",
    "# create a training data loader\n",
    "train_ds = monai.data.CacheDataset(data=data_train, transform=train_transforms, num_workers=4)\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "batch_size_train = 4\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size_train,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    pin_memory=torch.cuda.is_available(),\n",
    ")\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.CacheDataset(data=data_val, transform=val_transforms, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)\n",
    "# create a test data loader\n",
    "test_ds = monai.data.CacheDataset(data=data_test, transform=val_transforms, num_workers=4)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=4, collate_fn=list_data_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create VNet, DiceLoss, DiceMetric and Adam optimizer\n",
    "dice_metric = DiceMetric(include_background=True, to_onehot_y=False, sigmoid=True, reduction=\"mean\")\n",
    "device = torch.device(\"cuda:1\")\n",
    "# using MONAI Unet implementation for cuda optimizations\n",
    "# parametrize UNet like VNet (see: https://arxiv.org/abs/1606.04797): \n",
    "#   - 4x downsampling\n",
    "#   - 16/32/64/128/256 filter channels, \n",
    "#   - down/up-convolutions with stride 2 instead of max-pooling/up-pooling\n",
    "#   - number of residual units in each layer: 2 \n",
    "#   - Dice loss\n",
    "model = monai.networks.nets.UNet(\n",
    "    dimensions=3,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    dropout=0.5,\n",
    "    num_res_units=2).to(device)\n",
    "loss_function = monai.losses.DiceLoss(include_background=True, sigmoid=True, squared_pred=True)#\n",
    "optimizer = torch.optim.Adam(model.parameters(), 3e-4)\n",
    "model.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "export_tag = 'best_metric_model'\n",
    "val_interval = 1\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = list()\n",
    "metric_values = list()\n",
    "writer = SummaryWriter()\n",
    "n_epochs = 120\n",
    "for epoch in range(n_epochs):\n",
    "    t0 = time.time()\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{n_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "        writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    t1 = time.time()\n",
    "    print('Elapsed time for epoch: %0.2f sec.'%(t1-t0))\n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metric_sum = 0.0\n",
    "            metric_count = 0\n",
    "            val_images = None\n",
    "            val_labels = None\n",
    "            val_outputs = None\n",
    "            for val_data in val_loader:\n",
    "                val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                #roi_size = (96, 96, 96)\n",
    "                sw_batch_size = 4\n",
    "                #val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                val_outputs = model(val_images)\n",
    "                value = dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                metric_count += len(value)\n",
    "                metric_sum += value.item() * len(value)\n",
    "            metric = metric_sum / metric_count\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), export_tag+'.pth')\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                )\n",
    "            )\n",
    "            writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "            # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "            plot_2d_or_3d_image(val_images, epoch + 1, writer, index=0, tag=\"image\")\n",
    "            plot_2d_or_3d_image(val_labels, epoch + 1, writer, index=0, tag=\"label\")\n",
    "            plot_2d_or_3d_image(val_outputs, epoch + 1, writer, index=0, tag=\"output\")\n",
    "            t2 = time.time()\n",
    "            print('Elapsed time for validation eval: %0.2f sec.'%(t2-t1))\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training loss / validation metric, save in publication quality\n",
    "fig, axs = plt.subplots(1,2,figsize=(14,5),dpi=300)\n",
    "axs[0].plot(epoch_loss_values)\n",
    "axs[0].xaxis.set_ticks(np.arange(0, n_epochs, 10))\n",
    "axs[0].yaxis.set_ticks(np.linspace(0, 1, 21))\n",
    "axs[0].grid(True, color = '0.9')\n",
    "axs[0].set_title('Dice loss (train)\\n(Min loss %0.4f at epoch %d)'%(torch.min(torch.tensor(epoch_loss_values)),\n",
    "                                                                    torch.argmin(torch.tensor(epoch_loss_values)+1)))\n",
    "axs[1].plot(metric_values)\n",
    "axs[1].xaxis.set_ticks(np.arange(0, n_epochs, 10))\n",
    "axs[1].yaxis.set_ticks(np.linspace(0, 1, 21))\n",
    "axs[1].grid(True, color = '0.9')\n",
    "axs[1].set_title('Dice metric (validation)\\n(Max Dice %0.4f at epoch %d)'%(torch.max(torch.tensor(metric_values)),\n",
    "                                                                           torch.argmax(torch.tensor(metric_values)+1)))\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(export_tag+'_Scalars_DiceLossMetric.png',dpi=300)\n",
    "fig.savefig(export_tag+'_Scalars_DiceLossMetric.pdf',dpi=300)\n",
    "# also save the numpy arrays of loss and metric\n",
    "np.save(export_tag+'_Scalars_DiceLoss.npy',torch.tensor(epoch_loss_values).cpu().numpy())\n",
    "np.save(export_tag+'_Scalars_DiceValidationMetric.npy',torch.tensor(metric_values).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now, run the forward inference on validation set\n",
    "val_ds = monai.data.Dataset(data=data_val, transform=val_transforms)\n",
    "tmp_val_loader = DataLoader(val_ds, batch_size=1, num_workers=1, collate_fn=list_data_collate)\n",
    "\n",
    "# can load previously computed weights (if kernel restarted, or e.g. for fine-tuning)\n",
    "load_stored_weights = False\n",
    "if load_stored_weights:\n",
    "    device = torch.device(\"cuda:1\")\n",
    "    dice_metric = DiceMetric(include_background=True, to_onehot_y=False, sigmoid=True, reduction=\"mean\")\n",
    "    ff_model_weights = export_tag+'.pth'\n",
    "        model = monai.networks.nets.UNet(\n",
    "        dimensions=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        dropout=0.5,\n",
    "        num_res_units=2).to(device)\n",
    "    model.load_state_dict(torch.load(ff_model_weights))\n",
    "    model.eval()\n",
    "    \n",
    "t0 = time.time()\n",
    "times_elapsed = []\n",
    "inferer = SimpleInferer()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_images = []\n",
    "    val_labels = []\n",
    "    val_outputs = []\n",
    "    val_metrics = []\n",
    "    t0a = time.time()\n",
    "    for idx, val_data in enumerate(tmp_val_loader):\n",
    "        val_image, val_label = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "        val_output = inferer(val_image, model) \n",
    "        val_metric = dice_metric(y_pred=val_output, y=val_label)\n",
    "        # store results\n",
    "        val_images.append(val_image)\n",
    "        val_labels.append(val_label)\n",
    "        val_outputs.append(val_output)\n",
    "        val_metrics.append(val_metric.cpu().numpy())\n",
    "        print(f'Evaluated val vol {idx+1} of {len(val_loader)}')\n",
    "        times_elapsed.append(time.time()-t0a)\n",
    "        t0a = time.time()\n",
    "t1 = time.time()\n",
    "t_elapsed = (t1-t0)\n",
    "t_avg = t_elapsed/len(val_loader)\n",
    "t_avg2 = np.mean(times_elapsed)\n",
    "print(f'Total inference time for %d samples: %0.3f sec.'%(len(val_loader), t_elapsed))\n",
    "print(f'Average inference time: %0.3f sec (sd: %0.3f sec).'%(t_avg2, np.std(times_elapsed)))\n",
    "print(f'Speedup over ANTs segmentation (377 sec.): %0.2f'%(377/t_avg2))\n",
    "print(f'Dice metric stats:\\n{arrayStats(np.array(val_metrics))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training: plot inference result on validation set:\n",
    "normalizeTo01 = False\n",
    "nrcols = 5\n",
    "cropper = monai.transforms.CenterSpatialCrop([200, 150, 100])\n",
    "for idx, (img, seg, pred, dice) in enumerate(zip(val_images,\n",
    "                                                 val_labels,\n",
    "                                                 val_outputs,\n",
    "                                                 val_metrics)):\n",
    "    if idx!=10:\n",
    "        continue\n",
    "    print('Val sample: %d'%(idx))\n",
    "    print('Vol: %s'%(data_val[idx]['img']))\n",
    "    print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
    "    img = np.squeeze(img.cpu().numpy(),axis=0)\n",
    "    seg = np.squeeze(seg.cpu().numpy(),axis=0)\n",
    "    pred = np.squeeze(pred.cpu().numpy(),axis=0)\n",
    "    if normalizeTo01:\n",
    "        pred -= np.min(pred)\n",
    "        pred /= np.max(pred)\n",
    "    # plot the slice [:, :, slice_idx]\n",
    "    slice_idxs = (np.array([208, 160, 112])/2).astype(int)\n",
    "    plt.figure(\"check val sample %d\"%idx, (12, 6))\n",
    "    # plot along 1st axis\n",
    "    # img\n",
    "    slice_idx = slice_idxs[0]-10\n",
    "    plt.subplot(1, nrcols, 1)\n",
    "    plt.title(\"img\")\n",
    "    plt.imshow(np.squeeze(img[0,slice_idx, :, :]), cmap=\"gray\")\n",
    "    # seg\n",
    "    plt.subplot(1, nrcols, 2)\n",
    "    plt.title(\"seg\")\n",
    "    plt.imshow(np.squeeze(seg[0,slice_idx, :, :]))\n",
    "    # pred\n",
    "    plt.subplot(1, nrcols, 3)\n",
    "    plt.title(\"pred\")\n",
    "    plt.imshow(np.squeeze(pred[0,slice_idx, :, :]))\n",
    "    # pred sigmoid activate\n",
    "    pred_sig = np_sigmoid(pred)\n",
    "    plt.subplot(1, nrcols, 4)\n",
    "    plt.title(\"pred sigmoid\")\n",
    "    plt.imshow(np.squeeze(pred_sig[0,slice_idx, :, :]))\n",
    "    # pred|0.5\n",
    "    th = 0.5\n",
    "    plt.subplot(1, nrcols, 5)\n",
    "    plt.title(f\"pred > {th}\")\n",
    "    plt.imshow(np.squeeze(pred_sig[0,slice_idx, :, :]>th))\n",
    "    # overlay\n",
    "    # todo\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
